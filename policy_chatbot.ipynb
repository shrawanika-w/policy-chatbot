{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208a8b3b-0ef8-43a5-be3c-813f7cc61a91",
   "metadata": {},
   "source": [
    "### Nestle Policy Chatbot - Simplilearn Submission\n",
    "\n",
    "- **Name:** Shrawanika Wakde\n",
    "- **Email:** shrawanika@gmail.com\n",
    "- **Program:** Advanced Executive Program in Applied Generative AI\n",
    "- **Batch:** IITM AG June 2025 Cohort 1\n",
    "- **Date:** 2025-09-28\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413cd21-6cf5-424a-b906-5514eb2b1873",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "**Task:** Your task is to develop a conversational chatbot. This chatbot must answer queries about Nestlé's HR reports efficiently. Use Python libraries, OpenAI's GPT model, and Gradio UI. These tools will help you create a user-friendly interface. This interface will extract and process information from documents. It will provide accurate responses to user queries.\n",
    "\n",
    "**Action:**\n",
    "•\tImport essential tools and set up OpenAI's API environment.\n",
    "•\tLoad Nestle's HR policy using PyPDFLoader and split it for easy processing.\n",
    "•\tCreate vector representations for text chunks using Chroma dB and OpenAI's embeddings.\n",
    "•\tBuild a question-answering system using the GPT-3.5 Turbo model to retrieve answers from text chunks.\n",
    "•\tCreate a prompt template to guide the chatbot in understanding and responding to users.\n",
    "•\tUse Gradio to build a user-friendly chatbot interface, enabling interaction and information retrieval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ec64a-0515-4f99-85e1-d07c7077a7f2",
   "metadata": {},
   "source": [
    "## Challenges Encountered\n",
    "\n",
    "1. **Using static file input instead of UI upload**\n",
    "- Currently, the system relies on static PDF files rather than allowing users to upload documents through the UI.\n",
    "- Because of Gradio instability in JupyterLab, not using Gradio Upload Button which uses Blocks\n",
    "- Using Gradio Blocks sometimes causes random errors, making the interface unreliable in the lab environment.\n",
    "\n",
    "\n",
    "2. **Using FAISS instead of Chroma** : \n",
    "- ChromaDB requires SQLite, but the lab environment has an outdated, unsupported SQLite version.\n",
    "- This prevents creation of both in-memory and persistent vector stores.\n",
    "- Upgrading SQLite requires admin access, which is unavailable in the lab.\n",
    "- Attempts to use duckdb+parquet as a workaround fail because the installed Chroma version still depends on SQLite internally.\n",
    "- Due to SQLite constraints, FAISS is used as an alternative in-memory vector store.\n",
    "- FAISS avoids system-level dependencies, allowing embeddings and retrieval to work reliably in the lab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b86ae0bb-f425-4953-84b0-1a4d6a0e01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 2. Load PDF \n",
    "loader = PyPDFLoader(\"inputs/Nestle HR Policy.pdf\")  # replace with your PDF path\n",
    "documents = loader.load()\n",
    "\n",
    "# 3. Split Text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 4. Create embeddings and inmemory vector DB\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectordb = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# 5. Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"You are a helpful HR assistant. Use the context below to answer the question.\n",
    "        Context: {context}\\n\\nQuestion: {question}\\nAnswer:\"\"\"\n",
    ")\n",
    "\n",
    "# 6. Retriever Chain\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33c6aa35-e1cd-4b1b-81c2-d273d9926290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.44.1\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://28cc5052eeac7c985d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://28cc5052eeac7c985d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradio Interface\n",
    "import gradio as gr\n",
    "print(gr.__version__)\n",
    "\n",
    "def answer_question(query):\n",
    "    return qa.run(query)\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn = answer_question,\n",
    "     title = \"Nestle HR Policy Chatbot\",\n",
    "   \n",
    "    inputs = gr.Textbox(label=\"Ask about HR Policy\"),\n",
    "    outputs = gr.Textbox(label=\"Bot Answer\"),\n",
    "        \n",
    "    flagging_options = [\"incorrect response\"],  \n",
    "    flagging_dir = \"reported_responses\" # Reported repsonses will be saved under this folder in log.csv\n",
    ")\n",
    "    \n",
    "iface.launch(share=True) # Without share=true, it doesn not load interface inside the Lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fa12b8b-f854-4ecb-b487-b40b4d66aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "#iface.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb378b3-1519-4e7a-b6e6-1806326f06af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
